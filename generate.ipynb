{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fccdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1cd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the Avatar text for training\n",
    "file_name = \"transcript.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ebdd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a custom BPE Tokenizer on the downloaded text\n",
    "# This will save one file: `aitextgen.tokenizer.json`, which contains the\n",
    "# information needed to rebuild the tokenizer.\n",
    "train_tokenizer(file_name)\n",
    "tokenizer_file = \"aitextgen.tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd31888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2ConfigCPU is a mini variant of GPT-2 optimized for CPU-training\n",
    "# e.g. the # of input tokens here is 64 vs. 1024 for base GPT-2.\n",
    "config = GPT2ConfigCPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4489837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate aitextgen using the created tokenizer and config\n",
    "ai = aitextgen(tokenizer_file=tokenizer_file, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b01151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f455a7f7839d4dd7adafce0ba1dfb21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                 | 0/19984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can build datasets for training by creating TokenDatasets,\n",
    "# which automatically processes the dataset with the appropriate size.\n",
    "data = TokenDataset(file_name, tokenizer_file=tokenizer_file, block_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f14d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
      "/Users/alicheraghpour/miniforge3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:445: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicheraghpour/miniforge3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1788: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/Users/alicheraghpour/miniforge3/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e6575c087c4800a702ce3bdda9f6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                 | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " wholess, drilling.\n",
      "Aang\n",
      "Maybe you're making me.\n",
      "Aang\n",
      "We can do it.\n",
      "Katara\n",
      "We need to see it, but we'll be clear eat. And we're doing.\n",
      "Toph\n",
      "Ah, he's so much a\n",
      "==========\n",
      "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " the warden? No one ever might be better happy to get the Avatar.\n",
      "Aang\n",
      "Hey!\n",
      "Aang\n",
      "Where did you make that?\n",
      "Katara\n",
      "Aang, what?\n",
      "Sokka\n",
      "It's a confused.\n",
      "Sokka\n",
      "I'm doing it.\n",
      "Sokka\n",
      "\n",
      "==========\n",
      "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "Katara\n",
      "Appa, do you possibly readed to fight?\n",
      "Toph\n",
      "I'll never sneak me if you said that to pick up in once, can't really hear on. I didn't have a few field!\n",
      "Sokka\n",
      "==========\n",
      "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " about me. All right, that's good idea.\n",
      "Katara\n",
      "Please, Aang. Please, I'm sorry, but I'm not angrying you.\n",
      "Sokka\n",
      "No problem. You're not a kid.\n",
      "Toph\n",
      "Actually, but I know it. But\n",
      "==========\n",
      "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ", I wasn't there. I was still old enough to end it.\n",
      "Ying\n",
      "Ah, and maybe it's in.\n",
      "Yangchen\n",
      "The Boulder from the swamp.\n",
      "Forget about the trade of the state. Cou\n",
      "==========\n",
      "\u001b[1m30,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m30,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " #1\n",
      "You're the Avatar!\n",
      "Aang\n",
      "Great!\n",
      "Aang\n",
      "Now! I'm just saying anymore!\n",
      "Shyu\n",
      "Fine.\n",
      "Shyu\n",
      "Please, I'll be on the shipsqueaks this bativeday\n",
      "==========\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[1m35,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m35,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "! You're going to be a lot of things else!\n",
      "Katara\n",
      "Everyone has a choice!\n",
      "Sokka\n",
      "We need to do the top to the reavate.\n",
      "Aang\n",
      "Yeah, it's okay it. Welcompon of us.\n",
      "==========\n",
      "\u001b[1m40,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m40,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " and sad.\n",
      "Aang\n",
      "Great.\n",
      "Aang\n",
      "I'm sorry.\n",
      "Sokka\n",
      "I'm sorry, I'm going into that guy.\n",
      "Sokka\n",
      "I'm not sure about it! Your nomads are unless firebenders.\n",
      "Katara\n",
      "That's it!\n",
      "Sokka\n",
      "==========\n",
      "\u001b[1m45,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m45,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "! Where is the Fire Nation?\n",
      "Aang\n",
      "I don't know what I'm doing.  I'm just surprised my engies.\n",
      "Iroh\n",
      "What are you doing here?\n",
      "Zuko\n",
      "I don't need to do this.   What are you doing here?\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=50000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m50,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "?\n",
      "Zuko\n",
      "Good! We're here for the sunset to Ba Sing Se.\n",
      "Iroh\n",
      "Prince Zuko is only one thing to be the Fire Nation ships of the world. We deserve to defeat him and save our counts.\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "# Train the model! It will save pytorch_model.bin periodically and after completion to the `trained_model` folder.\n",
    "# On a 2020 8-core iMac, this took ~25 minutes to run.\n",
    "ai.train(data, batch_size=8, num_steps=50000, generate_every=5000, save_every=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82b54d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mZuko\u001b[0m\n",
      "Where are you here?\n",
      "Sokka\n",
      "Well, I don't know. What are you doing?  Well!\n",
      "Katara\n",
      "Stop!\n",
      "Sokka\n",
      "Nice try, Sokka.\n",
      "Katara\n",
      "You're right. I'm sure it'll be okay to be there.\n",
      "Katara\n",
      "\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "There's a little victory in the coolering, and sir?\n",
      "Toph\n",
      "I can get it. Snap that shows it off!\n",
      "Sokka\n",
      "The Boulder!\n",
      "Fire Nation Man\n",
      "Avatar Aang, daughter your\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "I'm so sorry to.\n",
      "Zuko\n",
      "Okay.\n",
      "Your uncle. We won't be able to serve this war.\n",
      "Iroh\n",
      "We will remember your destiny is became Lord.  And if you've never done some goodname.\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "I don't know.\n",
      "Bumi\n",
      "The count me inside, you're an extra, which!\n",
      "Bato\n",
      "It's a rot of your mouthucele.\n",
      "Merchanist\n",
      "Five, you are exated\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "Both, not you! I'm so smart, but I will never waited for your sick things, in the moment.\n",
      "Aang\n",
      "You know, I'm welcome here.\n",
      "Sokka\n",
      "I don't know what you're doing.\n",
      "Zuko\n",
      "How did\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "I'm sorry, but good timesmeaed.\n",
      "Zuko\n",
      "So what's the different?\n",
      "Zuko\n",
      "Sure is, Uncle! We're looking for the mother.\n",
      "Lee\n",
      "Do you even know?\n",
      "Zuko\n",
      "June\n",
      "No,\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "Wait,  I must be bother than hungry!\n",
      "Zuko\n",
      "What?\n",
      "Aang\n",
      "Well, look, I know.\n",
      "Sokka\n",
      "Ah! It's not just hard. I'm just a little hurt.\n",
      "Zuko\n",
      "Uncle, but Inn\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "You're here!\n",
      "Old man\n",
      "There's the challenges meet!\n",
      "Katara\n",
      "Hi, Dad! He won't be in your burn.\n",
      "Sokka\n",
      "That's impossible!\n",
      "Uh... what are you talking on?\n",
      "Zuko\n",
      "\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "You're talking about?\n",
      "Zuko\n",
      "I'm doing this.\n",
      "Iroh\n",
      "Run me please!\n",
      "Zuko\n",
      "The Avatar's father.  We have the rest. Seem yourself a plan. I've really had a different dragon.\n",
      "Iroh\n",
      "\n",
      "==========\n",
      "\u001b[1mZuko\u001b[0m\n",
      "I'm sure he's perfect to come up.\n",
      "Aang\n",
      "We'll keep flying.\n",
      "Katara\n",
      "So, we came together for my dad?\n",
      "Sokka\n",
      "What do you mean?\n",
      "Zuko\n",
      "Hey, sir. Where's going?\n",
      "Zuko\n",
      "Well\n"
     ]
    }
   ],
   "source": [
    "# Generate text from it!\n",
    "ai.generate(10, prompt=\"Zuko\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
